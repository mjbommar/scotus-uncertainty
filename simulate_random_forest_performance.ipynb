{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy\n",
    "import pandas\n",
    "import sklearn\n",
    "import sklearn.dummy\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Matplotlib setup\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load justice-centered SCDB data\n",
    "scdb_data = pandas.read_csv(\"data/SCDB_2013_01_justiceCentered_Citation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disposition outcoming coding\n",
    "\n",
    "  In the section below, we transform the SCDB vote and caseDisposition variables into an outcome variable indicating whether the case overall and each Justice has affirmed or reverse.\n",
    "  \n",
    "  * vote: [http://scdb.wustl.edu/documentation.php?var=vote#norms](http://scdb.wustl.edu/documentation.php?var=vote#norms)\n",
    "  * caseDisposition: [http://scdb.wustl.edu/documentation.php?var=caseDisposition#norms](http://scdb.wustl.edu/documentation.php?var=caseDisposition#norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setup the outcome map.\n",
    "\n",
    "Rows correspond to vote types.  Columns correspond to disposition types.\n",
    "\n",
    "Element values correspond to:\n",
    " * -1: no precedential issued opinion or uncodable, i.e., DIGs\n",
    " * 0: affirm, i.e., no change in precedent\n",
    " * 1: reverse, i.e., change in precent\n",
    "\"\"\"\n",
    "outcome_map = pandas.DataFrame([[-1, 0, 1, 1, 1, 0, 1, -1, -1, -1, -1],\n",
    "               [-1, 1, 0, 0, 0, 1, 0, -1, -1, -1, -1],\n",
    "               [-1, 0, 1, 1, 1, 0, 1, -1, -1, -1, -1],\n",
    "               [-1, 0, 1, 1, 1, 0, 1, -1, -1, -1, -1],\n",
    "               [-1, 0, 1, 1, 1, 0, 1, -1, -1, -1, -1],\n",
    "               [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
    "               [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
    "               [-1, 0, 0, 0, -1, 0, -1, -1, -1, -1, -1]])\n",
    "outcome_map.columns = range(1, 12)\n",
    "outcome_map.index = range(1, 9)\n",
    "\n",
    "def get_outcome(vote, disposition):\n",
    "    \"\"\"\n",
    "    Return the outcome code.\n",
    "    \"\"\"\n",
    "    if pandas.isnull(vote) or pandas.isnull(disposition):\n",
    "        return -1\n",
    "    \n",
    "    return outcome_map.loc[int(vote), int(disposition)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Map the case-level disposition outcome \n",
    "scdb_data.loc[:, \"case_outcome_disposition\"] = outcome_map.loc[1, scdb_data.loc[:, \"caseDisposition\"]].values\n",
    "scdb_data.loc[:, \"lc_case_outcome_disposition\"] = outcome_map.loc[1, scdb_data.loc[:, \"lcDisposition\"]].values\n",
    "\n",
    "# Map the justice-level disposition outcome\n",
    "scdb_data.loc[:, \"justice_outcome_disposition\"] = scdb_data.loc[:, (\"vote\", \"caseDisposition\")] \\\n",
    "    .apply(lambda row: get_outcome(row[\"vote\"], row[\"caseDisposition\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a simulation\n",
    "\n",
    "  In the section below, we define methods that handle the execution and analysis of simulations.  Simulations are based around the following concepts:\n",
    "  \n",
    "  * __pre-processing methods__: pre-processing methods handle cleaning, reshaping, transforming, and encoding input data\n",
    "  * __prediction methods__: prediction methods take historical data and determine, for each term-justice,  what prediction to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Court to circuit mapping, which maps from SCDB codebook to the actual Circuit number\n",
    "# http://scdb.wustl.edu/documentation.php?var=caseOrigin\n",
    "# http://scdb.wustl.edu/documentation.php?var=caseSource\n",
    "court_circuit_map = {1: 13,\n",
    "                     2: 13, 3: 13, 4: 14, 5: 14, 6: 13, 7: 13, 8: 13,\n",
    "                     9: 22, 10: 99, 12: 9, 13: 99, 14: 13, 15: 99, 16: 99,\n",
    "                     17: 99, 18: 99, 19: 0, 20: 22, 21: 1, 22: 2, 23: 3,\n",
    "                     24: 4, 25: 5, 26: 6, 27: 7, 28: 8, 29: 9, 30: 10,\n",
    "                     31: 11, 32: 12, 41: 11, 42: 11, 43: 11, 44: 9, 45: 9,\n",
    "                     46: 8, 47: 8, 48: 9, 49: 9, 50: 9, 51: 9, 52: 10, 53: 2,\n",
    "                     54: 3, 55: 12, 56: 11, 57: 11, 58: 11, 59: 11, 60: 11,\n",
    "                     61: 11, 62: 9, 63: 9, 64: 9, 65: 7, 66: 7, 67: 7, 68: 7,\n",
    "                     69: 7, 70: 8, 71: 8, 72: 10, 73: 6, 74: 6, 75: 5, 76: 5,\n",
    "                     77: 5, 78: 1, 79: 4, 80: 1, 81: 6, 82: 6, 83: 8, 84: 5,\n",
    "                     85: 5, 86: 8, 87: 8, 88: 9, 89: 8, 90: 9, 91: 1, 92: 3,\n",
    "                     93: 10, 94: 2, 95: 2, 96: 2, 97: 2, 98: 4, 99: 4, 100: 4,\n",
    "                     101: 8, 102: 9, 103: 6, 104: 6, 105: 10, 106: 10, 107: 10,\n",
    "                     108: 9, 109: 3, 110: 3, 111: 3, 112: 1, 113: 1, 114: 4,\n",
    "                     115: 8, 116: 6, 117: 6, 118: 6, 119: 5, 120: 5, 121: 5,\n",
    "                     122: 5, 123: 10, 124: 2, 125: 3, 126: 4, 127: 4, 128: 9,\n",
    "                     129: 9, 130: 4, 131: 4, 132: 7, 133: 7, 134: 10, 150: 5,\n",
    "                     151: 9, 152: 4, 153: 7, 155: 4, 160: 4, 162: 11, 163: 5,\n",
    "                     164: 11, 165: 7, 166: 7, 167: 8, 168: 6, 169: 5, 170: 8,\n",
    "                     171: 3, 172: 3, 173: 2, 174: 4, 175: 6, 176: 3, 177: 3,\n",
    "                     178: 5, 179: 4, 180: 4, 181: 7, 182: 6, 183: 3, 184: 9,\n",
    "                     185: 11, 186: 8, 187: 5, 300: 0, 301: 0, 302: 0, 400: 99,\n",
    "                     401: 99, 402: 99, 403: 11, 404: 8, 405: 9, 406: 2, 407: 3,\n",
    "                     408: 11, 409: 11, 410: 7, 411: 7, 412: 8, 413: 10, 414: 6,\n",
    "                     415: 5, 416: 1, 417: 4, 418: 1, 419: 6, 420: 8,\n",
    "                     421: 5, 422: 8, 423: 9, 424: 1, 425: 3, 426: 2,\n",
    "                     427: 4, 428: 6, 429: 9, 430: 3, 431: 1, 432: 4, 433: 6,\n",
    "                     434: 5, 435: 2, 436: 4, 437: 4, 438: 7,\n",
    "                     439: 10, 440: 12, 441: 8, 442: 10, 443: 9}\n",
    "\n",
    "\n",
    "def map_circuit(value):\n",
    "    try:\n",
    "        return court_circuit_map[value]\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# Get lists of classes for categorical vars\n",
    "# Issue area\n",
    "issue_area_codes = [0]\n",
    "issue_area_codes.extend(sorted(scdb_data['issueArea'].fillna(0).apply(int).unique().tolist()))\n",
    "\n",
    "# Issue\n",
    "issue_codes = [0]\n",
    "issue_codes.extend(sorted(scdb_data['issue'].fillna(0).apply(int).unique().tolist()))\n",
    "\n",
    "# Courts\n",
    "court_circuit_codes = [0]\n",
    "court_circuit_codes.extend(sorted(list(set(court_circuit_map.values()))))\n",
    "\n",
    "# Admin action\n",
    "admin_action_codes = [0]\n",
    "admin_action_codes.extend(sorted(scdb_data['adminAction'].fillna(0).apply(int).unique().tolist()))\n",
    "\n",
    "# Law types\n",
    "law_type_codes = [0]\n",
    "law_type_codes.extend(sorted(scdb_data['lawType'].fillna(0).apply(int).unique().tolist()))\n",
    "\n",
    "# Law supp types\n",
    "law_supp_codes = [0]\n",
    "law_supp_codes.extend(sorted(scdb_data['lawSupp'].fillna(0).apply(int).unique().tolist()))\n",
    "\n",
    "# Cert reason\n",
    "cert_reason_codes = [0]\n",
    "cert_reason_codes.extend(sorted(scdb_data['certReason'].fillna(0).apply(int).unique().tolist()))\n",
    "\n",
    "# Jurisdiction\n",
    "jurisdiction_codes = [0]\n",
    "jurisdiction_codes.extend(sorted(scdb_data['jurisdiction'].fillna(0).apply(int).unique().tolist()))\n",
    "\n",
    "# LC Disagreement\n",
    "lc_disagreement_codes = [0]\n",
    "lc_disagreement_codes.extend(sorted(scdb_data['lcDisagreement'].fillna(0).apply(int).unique().tolist()))\n",
    "\n",
    "# Justice codes\n",
    "justice_codes = [0]\n",
    "justice_codes.extend(sorted(scdb_data['justice'].fillna(0).apply(int).unique().tolist()))\n",
    "\n",
    "# Parties\n",
    "party_codes = [0]\n",
    "party_codes.extend(sorted(scdb_data['petitioner'].fillna(0).apply(int).unique()))\n",
    "party_codes.extend(sorted(scdb_data['respondent'].fillna(0).apply(int).unique()))\n",
    "party_codes = sorted(list(set(party_codes)))\n",
    "\n",
    "# LC outcome\n",
    "lc_case_outcome_codes = [0]\n",
    "lc_case_outcome_codes.extend(sorted(scdb_data['lc_case_outcome_disposition'].fillna(0).apply(int).unique().tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76037, 1057)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    Process SCDB data frame into features.\n",
    "    \"\"\"\n",
    "    # Encode admin action\n",
    "    admin_action_encoded = sklearn.preprocessing.label_binarize(data['adminAction'].fillna(0).apply(int),\n",
    "                                                      admin_action_codes)\n",
    "    # Encode issue area\n",
    "    issue_area_encoded = sklearn.preprocessing.label_binarize(data['issueArea'].fillna(0).apply(int),\n",
    "                                                      issue_area_codes)\n",
    "\n",
    "    issue_encoded = sklearn.preprocessing.label_binarize(data['issue'].fillna(0).apply(int),\n",
    "                                                      issue_codes)\n",
    "    # Encode law type, cert reason, and jurisdiction\n",
    "    law_type_encoded = sklearn.preprocessing.label_binarize(data['lawType'].fillna(0).apply(int),\n",
    "                                                      law_type_codes)\n",
    "\n",
    "    law_supp_encoded = sklearn.preprocessing.label_binarize(data['lawSupp'].fillna(0).apply(int),\n",
    "                                                      law_type_codes)\n",
    "\n",
    "\n",
    "    cert_reason_encoded = sklearn.preprocessing.label_binarize(data['certReason'].fillna(0).apply(int),\n",
    "                                                      cert_reason_codes)\n",
    "\n",
    "    jurisdiction_encoded = sklearn.preprocessing.label_binarize(data['jurisdiction'].fillna(0).apply(int),\n",
    "                                                      jurisdiction_codes)\n",
    "    # Encode courts\n",
    "    data.loc[:, 'case_source_map'] = data['caseSource'].apply(map_circuit).apply(int)\n",
    "    data.loc[:, 'case_origin_map'] = data['caseOrigin'].apply(map_circuit).apply(int)\n",
    "\n",
    "    case_source_encoded = sklearn.preprocessing.label_binarize(data['case_source_map'].fillna(0).apply(int),\n",
    "                                                      court_circuit_codes)\n",
    "    case_origin_encoded = sklearn.preprocessing.label_binarize(data['case_origin_map'].fillna(0).apply(int),\n",
    "                                                      court_circuit_codes)\n",
    "\n",
    "    # Encode parties\n",
    "    petitioner_encoded = sklearn.preprocessing.label_binarize(data['petitioner'].fillna(0).apply(int),\n",
    "                                                              party_codes)\n",
    "    respondent_encoded = sklearn.preprocessing.label_binarize(data['respondent'].fillna(0).apply(int),\n",
    "                                                              party_codes)\n",
    "\n",
    "    # Justice\n",
    "    justice_encoded = sklearn.preprocessing.label_binarize(data['justice'].fillna(0).apply(int),\n",
    "                                                              justice_codes)\n",
    "    \n",
    "    lc_outcome_encoded = sklearn.preprocessing.label_binarize(data['lc_case_outcome_disposition'].fillna(0).apply(int),\n",
    "                                                  lc_case_outcome_codes)\n",
    "    \n",
    "    return numpy.hstack((justice_encoded, admin_action_encoded, issue_area_encoded, issue_encoded,\n",
    "                         law_type_encoded, law_supp_encoded, cert_reason_encoded, jurisdiction_encoded,\n",
    "                         case_source_encoded, case_origin_encoded, petitioner_encoded, respondent_encoded,\n",
    "                         lc_outcome_encoded))\n",
    "\n",
    "# Test shape\n",
    "scdb_feature_data = preprocess_data(scdb_data)\n",
    "print(scdb_feature_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_rf(historical_data, current_data, max_leaf_nodes=1024, n_estimators=1000):\n",
    "    \"\"\"\n",
    "    Prediction method based on simple random forest classifier.\n",
    "    \n",
    "    :param historical_data: SCDB DataFrame to use for out-of-sample calculationi; must be a subset of SCDB justice-centered \n",
    "      data known up to point in time\n",
    "    :param current_data: SCDB DataFrame to use to generate predictions\n",
    "\n",
    "    :return: vector containing predictions for each current_data record\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get features and targets\n",
    "    feature_train_data = preprocess_data(historical_data)\n",
    "    target_train_data = historical_data.loc[:, \"justice_outcome_disposition\"].values\n",
    "    target_index = (target_train_data >= 0)\n",
    "    \n",
    "    # Train model\n",
    "    model = sklearn.ensemble.RandomForestClassifier(max_leaf_nodes=max_leaf_nodes,\n",
    "                                                    n_estimators=n_estimators,\n",
    "                                                    min_samples_leaf=2)\n",
    "    model.fit(feature_train_data[target_index, :], target_train_data[target_index])\n",
    "    prediction_score = model.predict_proba(preprocess_data(current_data))\n",
    "    return prediction_score[:, 1]\n",
    "\n",
    "def run_simulation(simulation_data, term_list,  prediction_method, score_method=\"binary\"):\n",
    "    \"\"\"\n",
    "    This method defines the simulation driver.\n",
    "    \n",
    "    :param simulation_data: SCDB DataFrame to use for simulation; must be a subset of SCDB justice-centered data\n",
    "    :param term_list: list of terms to simulate, e.g., [2000, 2001, 2002]\n",
    "    :param prediction_method: method that takes historical data and indicates, by justice,  predictions for term\n",
    "    :param score_method: \"binary\" or \"stratified\"; binary maps to score >= 0.5, stratified maps to score <= random\n",
    "    :return: copy of simulation_data with additional columns representing predictions\n",
    "    \"\"\"\n",
    "    # Initialize predictions\n",
    "    return_data = simulation_data.copy()\n",
    "    return_data.loc[:, \"prediction\"] = numpy.nan\n",
    "    return_data.loc[:, \"prediction_score\"] = numpy.nan\n",
    "\n",
    "    # Iterate over all terms\n",
    "    for term in term_list:\n",
    "        print(term)\n",
    "        # Get indices for dockets to predict and use for historical data\n",
    "        before_term_index = simulation_data.loc[:, \"term\"] < term\n",
    "        current_term_index = (simulation_data.loc[:, \"term\"] == term) & (simulation_data.loc[:, \"justice_outcome_disposition\"] >= 0)\n",
    "\n",
    "        # Get the list of justices\n",
    "        term_justices = sorted(simulation_data.loc[current_term_index, \"justice\"].unique().tolist())\n",
    "\n",
    "        # Get the predictions\n",
    "        return_data.loc[current_term_index, \"prediction_score\"] =  prediction_method(simulation_data.loc[before_term_index, :],\n",
    "                                                                                simulation_data.loc[current_term_index, :])\n",
    "\n",
    "        # Support both most_frequent and stratified approaches\n",
    "        if score_method == \"binary\":\n",
    "            return_data.loc[current_term_index, \"prediction\"] = (return_data.loc[current_term_index, \"prediction_score\"] >= 0.5).apply(int)\n",
    "        elif score_method == \"stratified\":\n",
    "            return_data.loc[current_term_index, \"prediction\"] = (return_data.loc[current_term_index, \"prediction_score\"] >= numpy.random.random(return_data.loc[current_term_index].shape[0])).apply(int)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    # Get the return range and return\n",
    "    term_index = return_data.loc[:, \"term\"].isin(term_list) & (return_data.loc[:, \"justice_outcome_disposition\"] >= 0)\n",
    "    return return_data.loc[term_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "start_term = 1953\n",
    "end_term = 2013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting case outcomes with a random forest\n",
    "\n",
    "  In the simulation below, we demonstrate the performance of the baseline model to predict case outcome based solely on historical court reversal rate.\n",
    "  \n",
    "  The results indicate an accuracy of 63.72% with a frequency-weighted F1 score of 49.6%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_tree\n",
      "1953"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run simulation for simplest model\n",
    "print(\"predict_tree\")\n",
    "output_data = run_simulation(scdb_data, range(start_term, end_term), predict_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Analyze results\n",
    "print(sklearn.metrics.classification_report(output_data[\"justice_outcome_disposition\"],\n",
    "                                      output_data[\"prediction\"]))\n",
    "print(sklearn.metrics.confusion_matrix(output_data[\"justice_outcome_disposition\"],\n",
    "                                      output_data[\"prediction\"]))\n",
    "print(sklearn.metrics.accuracy_score(output_data[\"justice_outcome_disposition\"],\n",
    "                                      output_data[\"prediction\"]))\n",
    "print(sklearn.metrics.f1_score(output_data[\"justice_outcome_disposition\"],\n",
    "                                      output_data[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get accuracy over time\n",
    "output_data.loc[:, \"correct\"] = (output_data[\"justice_outcome_disposition\"] == output_data[\"prediction\"])\n",
    "court_case_accuracy_by_year = output_data.groupby(\"term\")[\"correct\"].mean()\n",
    "court_case_accuracy_by_year.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run vote simulation\n",
    "output_data.loc[:, \"case_prediction\"] = numpy.nan\n",
    "\n",
    "# Iterate over all dockets\n",
    "for docket_id, docket_data in output_data.groupby('docketId'):\n",
    "    # Count predictions from docket\n",
    "    output_data.loc[:, \"case_prediction\"]  = int(docket_data.loc[:, \"prediction\"].value_counts().idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(output_data[\"case_outcome_disposition\"].fillna(-1),\n",
    "                                      output_data[\"case_prediction\"].fillna(-1)))\n",
    "print(sklearn.metrics.confusion_matrix(output_data[\"case_outcome_disposition\"].fillna(-1),\n",
    "                                      output_data[\"case_prediction\"].fillna(-1)))\n",
    "print(sklearn.metrics.accuracy_score(output_data[\"case_outcome_disposition\"].fillna(-1),\n",
    "                                      output_data[\"case_prediction\"].fillna(-1)))\n",
    "print(sklearn.metrics.f1_score(output_data[\"case_outcome_disposition\"].fillna(-1),\n",
    "                                      output_data[\"case_prediction\"].fillna(-1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}